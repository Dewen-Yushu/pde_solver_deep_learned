{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('../../../pdl/pdl/utils/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from logs import enable_logging, logging \n",
    "from importlib import reload\n",
    "import iterativeMethods as im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable_logging(lvl=100)\n",
    "A = np.array([[2, 1], [5, 7]])\n",
    "f = np.array([11, 13])\n",
    "\n",
    "u, res = im.jacobi(A, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the real Jacobi method instead the spectral radius of the updating matrix is < 1.\n",
    "For the real Jacobi methods it holds the fact that if the matrix is diagonally dominant then the spectral radius of the updating matrix is guaranteed to be < 1. (http://www.cs.unipr.it/~bagnara/Papers/PDF/SIREV95.pdf)\n",
    "This condition does not hold for the paper Jacobi method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobi_eig = np.linalg.eigvals(np.linalg.inv(np.diag(np.diag(A))).dot(A-np.diag(np.diag(A))))\n",
    "spectral_radius = np.max(np.abs(jacobi_eig))\n",
    "print(spectral_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the matrix A for the 2D Poisson problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "A = np.eye(N**2)\n",
    "# Domani length\n",
    "L = 1.0\n",
    "# Cell size\n",
    "h = L/(N-1)\n",
    "\n",
    "# set homegenous dirichlet BC value\n",
    "b = 1.0\n",
    "\n",
    "#Initilize forcing term\n",
    "f = np.ones(N**2)*b\n",
    "\n",
    "for i in range(N, N**2-N):\n",
    "    if (i%N != 0 and i%N != N-1):\n",
    "        # Left and right neigh\n",
    "        A[i][i-1] = -0.25 \n",
    "        A[i][i+1] = -0.25\n",
    "        # Up and low neigh\n",
    "        A[i][i-N] = -0.25 \n",
    "        A[i][i+N] = -0.25 \n",
    "        # set forcing term\n",
    "        f[i] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the solution with jacobi method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, res = im.jacobi(A, f, max_iters=10000,tol = 1e-3)\n",
    "#u = np.linalg.inv(A).dot(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the solution\n",
    "Nice reference for contour plots https://www.python-course.eu/matplotlib_contour_plot.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, L, N)\n",
    "y = np.linspace(0, L, N)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = np.reshape(u, [N, N])\n",
    "plt.figure()\n",
    "cp = plt.contourf(X, Y, Z)\n",
    "plt.colorbar(cp)\n",
    "plt.title('Filled Contours Plot')\n",
    "plt.xlabel('x [-]')\n",
    "plt.ylabel('y [-]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the same solution with reset operator G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 35\n",
    "a = np.ones(N**2)\n",
    "b = -np.ones(N**2-1)*0.25\n",
    "c = -np.ones(N**2-N)*0.25\n",
    "\n",
    "A = np.diag(a) + np.diag(b, 1) + np.diag(b, -1) + np.diag(c, N) + np.diag(c, -N)\n",
    "#print(A)\n",
    "\n",
    "\n",
    "b_top_idx = np.arange(N)\n",
    "b_bottom_idx = np.arange(N**2-N, N**2)\n",
    "b_left_idx = np.linspace(N, N**2-2*N, N-2, dtype = int)\n",
    "b_right_idx = np.linspace(2*N-1, N**2-N-1, N-2, dtype = int)\n",
    "\n",
    "\n",
    "print(b_top_idx)\n",
    "print(b_bottom_idx)\n",
    "print(b_left_idx)\n",
    "print(b_right_idx)\n",
    "\n",
    "b_idx = np.append(b_top_idx, b_bottom_idx)\n",
    "b_idx = np.append(b_idx, b_left_idx)\n",
    "b_idx = np.append(b_idx, b_right_idx)\n",
    "#print(b_idx)\n",
    "b = np.ones(np.shape(b_idx))*3.0\n",
    "#print(b)\n",
    "f = np.ones(N**2)\n",
    "\n",
    "u, res = im.jacobi(A, f, b_idx = b_idx, b = b,max_iters=1000,tol = 1e-2)\n",
    "\n",
    "x = np.linspace(0, L, N)\n",
    "y = np.linspace(0, L, N)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = np.reshape(u, [N, N])\n",
    "plt.figure()\n",
    "cp = plt.contourf(X, Y, Z)\n",
    "plt.colorbar(cp)\n",
    "plt.title('Filled Contours Plot')\n",
    "plt.xlabel('x [-]')\n",
    "plt.ylabel('y [-]')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# One convolution with a 3x3 kernel\n",
    "#net = nn.Conv2d(1, 1, 3, padding=1, bias=False)\n",
    "\n",
    "# Do we want to use 3 layers?\n",
    "jac = nn.Conv2d(1, 1, 3, padding=1, bias=False)\n",
    "\n",
    "initial_weights = torch.zeros(1,1,3,3)\n",
    "initial_weights[0,0,0,1] = 0.25\n",
    "initial_weights[0,0,2,1] = 0.25\n",
    "initial_weights[0,0,1,0] = 0.25\n",
    "initial_weights[0,0,1,2] = 0.25\n",
    "jac.weight = nn.Parameter(initial_weights)\n",
    "\n",
    "for param in jac.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for name, param in jac.named_parameters():\n",
    "    print(name, param)\n",
    "\n",
    "\n",
    "    \n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 1, 3, padding=1, bias=False),\n",
    "    nn.Conv2d(1, 1, 3, padding=1, bias=False),\n",
    "    nn.Conv2d(1, 1, 3, padding=1, bias=False),\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize the wights s.t. H corresponds T (see 2.3.1)\n",
    "#initial_weights = torch.rand(1,1,3,3)*0.01\n",
    "#initial_weights[0,0,0,1] = 0.25\n",
    "#initial_weights[0,0,2,1] = 0.25\n",
    "#initial_weights[0,0,1,0] = 0.25\n",
    "#initial_weights[0,0,1,2] = 0.25\n",
    "#initial_weights[0,0,1,1] = 1.0\n",
    "#net.weight = nn.Parameter(initial_weights)\n",
    "\n",
    "# Set the optimizer, you have to play with lr: if too big nan\n",
    "optim = torch.optim.SGD(net.parameters(), lr=1e-6)\n",
    "#optim = torch.optim.Adam(net.parameters(), lr=1e-6)\n",
    "#optim = torch.optim.ASGD(net.parameters())\n",
    "# SGD is much faster\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build G matrix and B to reset the boundaries\n",
    "G = np.eye(N**2)\n",
    "G[b_idx, b_idx] -= 1\n",
    "B = np.zeros(N**2)\n",
    "B[b_idx] = b\n",
    "\n",
    "# Convert G and B to torch\n",
    "Bt = torch.zeros(1,1,N**2,1)\n",
    "Bt[0, 0, :,0] = torch.from_numpy(B)\n",
    "Gt = torch.zeros(1,1,N**2,N**2)\n",
    "Gt[0,0,:, :] = torch.from_numpy(G)\n",
    "\n",
    "# Build T matrix for standard jacobi iteration\n",
    "I = torch.zeros(1,1,N**2,N**2)\n",
    "I[0,0,:,:] = torch.eye(N**2,N**2)\n",
    "At = torch.zeros(1,1,N**2,N**2)\n",
    "At[0,0,:, :] = torch.from_numpy(A)\n",
    "T = I - At\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is obtained applying k times G(Tu+net(Tu)+f+net(f)-net(u)) + B = G(Tu+HTu+f+Hf-Hu) + B.\n",
    "G is the I with zeros in the boundary nodes\n",
    "B is a vector with the boundary values in the boundary nodes and zeros elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over problem istances(TOADD) and k \n",
    "for _ in range(10):\n",
    "    net.zero_grad()\n",
    "    # Sample k and u0\n",
    "    #k = 300\n",
    "    k = np.random.randint(1,20)\n",
    "    u0 = torch.randn(1, 1, N**2, 1, requires_grad=True)\n",
    "    \n",
    "    b = np.random.rand(np.shape(b_idx)[0])*3.0\n",
    "    B = np.zeros(N**2)\n",
    "    B[b_idx] = b\n",
    "    # Convert G and B to torch\n",
    "    Bt = torch.zeros(1,1,N**2,1)\n",
    "    Bt[0, 0, :,0] = torch.from_numpy(B)\n",
    "\n",
    "    \n",
    "    # Solve the same problem, at each iteration the only thing changing are the weights, which are optimized\n",
    "    for _ in range(100):\n",
    "        \n",
    "\n",
    "        # Initialize f: we use a zero forcing term for training\n",
    "        f = np.zeros(N**2)\n",
    "        ft = torch.zeros(1, 1, N**2, 1)\n",
    "        #ft[0,0,:,0] = torch.from_numpy(f)\n",
    "        \n",
    "        # Compute ustar = gtt ground truth solution torch TODO obtain ground_truth with LU factorization much faster\n",
    "        ground_truth, _ = im.jacobi(A, f, b_idx = b_idx, b = b,max_iters=1000,tol = 1e-7)\n",
    "        gtt = torch.zeros(1,1,N**2, 1)\n",
    "        gtt[0, 0, :, 0] = torch.from_numpy(ground_truth)\n",
    "\n",
    "        # Initialize output \n",
    "        output = Gt@(u0) + Bt\n",
    "        \n",
    "        # Obtain solution by iteratink k times, applyng the net is equivalent to pre-multiply by H\n",
    "        for _ in range(k):\n",
    "            # The two exression should be equivalent\n",
    "            #output = Gt@(T@(output) + Gt@(net((Gt@(T@(output)+ft)+Bt).view(1,1,N, N) - output.view(1,1,N, N)).view(1, 1,N**2, 1)) + ft ) + Bt\n",
    "            output = Gt@(T@(output) + ft) + Bt + Gt@(net((Gt@(T@(output)+ft)+Bt).view(1,1,N, N) - output.view(1,1,N, N)).view(1, 1,N**2, 1)) \n",
    "            #output = Gt@((jac(output).view(1,1,N, N)).view(1, 1,N**2, 1) + ft) + Bt + Gt@(net((Gt@(T@(output)+ft)+Bt).view(1,1,N, N) - output.view(1,1,N, N)).view(1, 1,N**2, 1)) \n",
    "\n",
    "        # Define the loss, CHECK if it is correct wrt paper\n",
    "        loss = F.mse_loss(gtt, output)\n",
    "        \n",
    "        \"\"\"\n",
    "        factor = 1.0\n",
    "        for name, param in net.named_parameters():\n",
    "            loss += factor *(torch.sum(param))\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        if loss <= 1e-6:\n",
    "            break\n",
    "            \n",
    "        # Backpropagation\n",
    "        loss.backward(retain_graph=False)\n",
    "        \n",
    "        # SGD step\n",
    "        optim.step()\n",
    "        \n",
    "        # Store lossses for visualization\n",
    "        losses.append(loss.item())\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "color_map = plt.get_cmap('cubehelix')\n",
    "colors = color_map(np.linspace(0.1, 1, 10))\n",
    "\n",
    "losses_fig = plt.figure()\n",
    "n_iter = np.arange(np.shape(losses)[0])\n",
    "plt.plot(n_iter, losses, color = colors[0], linewidth = 1, linestyle = \"-\", marker = \"\",  label='Loss')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(0., -0.3), loc=3, borderaxespad=0.)\n",
    "plt.xlabel('n iteration', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.title('Loss')\n",
    "plt.grid(True, which = \"both\", linewidth = 0.5,  linestyle = \"--\")\n",
    "\n",
    "print(\"final loss is {0}\".format(losses[-1]))\n",
    "#losses_fig.savefig('gridSearch.eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare solution obtained with ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "# Initialize u0\n",
    "#a = np.random.rand(N**2)\n",
    "output = torch.ones(1, 1, N**2, 1, requires_grad=False)\n",
    "#output[0,0,:,0] = torch.from_numpy(a, requires_grad=True)\n",
    "output = Gt@(output) + Bt\n",
    "\n",
    "# Initialize f randomly\n",
    "f = np.random.rand(N**2)\n",
    "f = np.ones(N**2)\n",
    "ft = torch.ones(1, 1, N**2, 1)\n",
    "ft[0,0,:,0] = torch.from_numpy(f)\n",
    "\n",
    "# Compute ustar = gtt ground truth solution torch\n",
    "ground_truth, _ = im.jacobi(A, f, b_idx = b_idx, b = b,max_iters=10000,tol = 1e-7)\n",
    "gtt = torch.zeros(1,1,N**2, 1)\n",
    "gtt[0, 0, :, 0] = torch.from_numpy(ground_truth)\n",
    "\n",
    "for _ in range(k):\n",
    "    #output = Gt@(T@(output) + Gt@(net((Gt@(T@(output)+ft)+Bt).view(1,1,N, N) - output.view(1,1,N, N)).view(1, 1,N**2, 1)) + ft ) + Bt\n",
    "    output = Gt@(T@(output) + ft) + Bt + Gt@(net((Gt@(T@(output)+ft)+Bt).view(1,1,N, N) - output.view(1,1,N, N)).view(1, 1,N**2, 1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F.mse_loss(gtt, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
